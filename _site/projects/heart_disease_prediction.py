# -*- coding: utf-8 -*-
"""Heart_Disease_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Mxs8513/mxs8513.github.io/blob/main/Heart_Disease_Prediction.ipynb

Importing Dependencies
"""

import numpy as np  # numpy arrays (lists)
import pandas as pd # used to create data frame (structure sheet)
from sklearn.model_selection import train_test_split # Split original dta into train and test data
from sklearn.linear_model import LogisticRegression # Graph
from sklearn.metrics import accuracy_score # Shows how model is running like how good

"""Data Collection and Processing"""

# loading the csv data to Pandas DataFrame which is structured Data Frames
heart_data = pd.read_csv('/content/data.csv') # read the csv file and store into a pandas

# print first 5 rows of the dta set
heart_data.head() # .head prints first 5 rows of dta set

# print Last 5 rwos of dta set
heart_data.tail() # .tail prints last 5 rows

# number of rows and columns in the dtaset
heart_data.shape # .shape function shows rows and columns

# getting some info about the dta
heart_data.info()

# checking for missing values
heart_data.isnull().sum() # gives the number of missing values in each columnn

# statistical measures about the dta
heart_data.describe()# General info about dta overall
# 0 represents the person doesen't have any heart effect
# 1 represents the person has some heart disease prob

# Checking the distribution of Target Variable
heart_data['target'].value_counts() # tells you how many values are 0 and how many values are one
# 165 people have a deffective heart
# 138 people do not have any heart disease problem

"""1 ---> Defective Heart
0 ---> Healthy Heart

Splitting the Features and Target
"""

# Every other Columnn is Features....Only the last one is Targets

x = heart_data.drop(columns='target', axis =1) # In the heart data set you are droping columnns target and you have to make sure to include axis = 1
y = heart_data['target'] # Brought the target columnn into a seperate/different place

print(x)
# Does not contain Target Columnn

print(y)
#Contains Target Columnn

"""Splitting the Data into Training Data and Test data"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2 )
# test size = 0.2 --- represents how much representaion you want in this case would be 20 percent
# stratify = y ----split the data and make sure both x and y don't get mixed up and will be presented in even matter
# Random State = 2 -- Split the data in a specific way

print(x.shape, x_train.shape, x_test.shape)
# 100 pecent is the 303,13
# 80 percent is the 242 13 which goes into training data
# 20 perecnt is the 61 13 which goes into testing data

"""Model Training

Logistic Regression Model
"""

model = LogisticRegression()

# Training the LogisticRegression Model with training Data
model.fit(x_train, y_train) # It will find the relationship bertween the data values and link them to the target values

"""Model Evaluation

Accuarcy Score
"""

# accuracy on training data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction, y_train)
# This will try to get a percentage of how accurate the x train model is predicting and relating that to y train

print('Accuracy on Training Data : ' , training_data_accuracy)
# The bottom score means out of a 100 values the model can predict about 85 values correctly

# accuracy on test data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction, y_test)

print('Accuracy on Training Data : ' , test_data_accuracy)

"""Building a Predicitve System"""

input_data = input_data = (67,1,0,160,286,0,0,108,1,1.5,1,3,2) # chaing from dumple to numpy
# change the input data to a numpy array

input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for only one instance

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)


# We have to input all the features and from there the model has to predict whether it is 0 or 1

# This was correct as ir predicted the right value

if (prediction[0]==0): #
  print('The Person does not have a Heart Disease')

else:
  print('The person has Heart Disease')

 # chaing from dumple to numpy
# change the input data to a numpy array

input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for only one instance

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)


# We have to input all the features and from there the model has to predict whether it is 0 or 1

# This was correct as ir predicted the right value

if (prediction[0]==0): #
  print('The Person does not have a Heart Disease')

else:
  print('The person has Heart Disease')

